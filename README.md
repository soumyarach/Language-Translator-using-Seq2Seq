# Language-Translator-using-Seq2Seq
# What I Built:
A simple English-French translator using a sequence-to-sequence model with attention, leveraging Keras and LSTM layers to learn translation patterns from a small dataset.

# How I Built It:

1. Data Preparation: Utilized a small dataset of English-French pairs to train the model.
2. Model Architecture: Designed an encoder-decoder model with LSTM layers, incorporating attention mechanisms to enhance translation accuracy.
3. Training: Trained the model using sparse categorical cross-entropy loss and Adam optimizer.
4. Inference: Implemented a translation function to generate French translations from English input sentences.

# Why I Built It:
To explore the capabilities of sequence-to-sequence models in language translation tasks, and to create a foundational project that can be expanded upon for more complex translation tasks or multilingual support.

# Key Features:

- Translate English sentences to French
- View translation history
- Potential for future improvements, such as increasing dataset size, fine-tuning model architecture, and adding more languages.
